{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n",
      "env: LD_LIBRARY_PATH=~/.conda/envs/jax/lib/\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "# CUDNN 8.2.1 in jax conda env\n",
    "%env LD_LIBRARY_PATH=~/.conda/envs/jax/lib/\n",
    "import array\n",
    "import functools as ft\n",
    "import gzip\n",
    "import os\n",
    "import struct\n",
    "import urllib.request\n",
    "\n",
    "import diffrax as dfx  # https://github.com/patrick-kidger/diffrax\n",
    "import einops  # https://github.com/arogozhnikov/einops\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import matplotlib.pyplot as plt\n",
    "import optax  # https://github.com/deepmind/optax\n",
    "\n",
    "import equinox as eqx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixerBlock(eqx.Module):\n",
    "    patch_mixer: eqx.nn.MLP\n",
    "    hidden_mixer: eqx.nn.MLP\n",
    "    norm1: eqx.nn.LayerNorm\n",
    "    norm2: eqx.nn.LayerNorm\n",
    "\n",
    "    def __init__(\n",
    "        self, num_patches, hidden_size, mix_patch_size, mix_hidden_size, *, key\n",
    "    ):\n",
    "        tkey, ckey = jr.split(key, 2)\n",
    "        self.patch_mixer = eqx.nn.MLP(\n",
    "            num_patches, num_patches, mix_patch_size, depth=1, key=tkey\n",
    "        )\n",
    "        self.hidden_mixer = eqx.nn.MLP(\n",
    "            hidden_size, hidden_size, mix_hidden_size, depth=1, key=ckey\n",
    "        )\n",
    "        self.norm1 = eqx.nn.LayerNorm((hidden_size, num_patches))\n",
    "        self.norm2 = eqx.nn.LayerNorm((num_patches, hidden_size))\n",
    "\n",
    "    def __call__(self, y):\n",
    "        y = y + jax.vmap(self.patch_mixer)(self.norm1(y))\n",
    "        y = einops.rearrange(y, \"c p -> p c\")\n",
    "        y = y + jax.vmap(self.hidden_mixer)(self.norm2(y))\n",
    "        y = einops.rearrange(y, \"p c -> c p\")\n",
    "        return y\n",
    "\n",
    "\n",
    "class Mixer2d(eqx.Module):\n",
    "    conv_in: eqx.nn.Conv2d\n",
    "    conv_out: eqx.nn.ConvTranspose2d\n",
    "    blocks: list\n",
    "    norm: eqx.nn.LayerNorm\n",
    "    t1: float\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_size,\n",
    "        patch_size,\n",
    "        hidden_size,\n",
    "        mix_patch_size,\n",
    "        mix_hidden_size,\n",
    "        num_blocks,\n",
    "        t1,\n",
    "        *,\n",
    "        key,\n",
    "    ):\n",
    "        input_size, height, width = img_size\n",
    "        assert (height % patch_size) == 0\n",
    "        assert (width % patch_size) == 0\n",
    "        num_patches = (height // patch_size) * (width // patch_size)\n",
    "        inkey, outkey, *bkeys = jr.split(key, 2 + num_blocks)\n",
    "\n",
    "        self.conv_in = eqx.nn.Conv2d(\n",
    "            input_size + 1, hidden_size, patch_size, stride=patch_size, key=inkey\n",
    "        )\n",
    "        self.conv_out = eqx.nn.ConvTranspose2d(\n",
    "            hidden_size, input_size, patch_size, stride=patch_size, key=outkey\n",
    "        )\n",
    "        self.blocks = [\n",
    "            MixerBlock(\n",
    "                num_patches, hidden_size, mix_patch_size, mix_hidden_size, key=bkey\n",
    "            )\n",
    "            for bkey in bkeys\n",
    "        ]\n",
    "        self.norm = eqx.nn.LayerNorm((hidden_size, num_patches))\n",
    "        self.t1 = t1\n",
    "\n",
    "    def __call__(self, t, y):\n",
    "        t = t / self.t1\n",
    "        _, height, width = y.shape\n",
    "        t = einops.repeat(t, \"-> 1 h w\", h=height, w=width)\n",
    "        y = jnp.concatenate([y, t])\n",
    "        y = self.conv_in(y)\n",
    "        _, patch_height, patch_width = y.shape\n",
    "        y = einops.rearrange(y, \"c h w -> c (h w)\")\n",
    "        for block in self.blocks:\n",
    "            y = block(y)\n",
    "        y = self.norm(y)\n",
    "        y = einops.rearrange(y, \"c (h w) -> c h w\", h=patch_height, w=patch_width)\n",
    "        return self.conv_out(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_loss_fn(model, weight, int_beta, data, t, key):\n",
    "    mean = data * jnp.exp(-0.5 * int_beta(t))\n",
    "    var = jnp.maximum(1 - jnp.exp(-int_beta(t)), 1e-5)\n",
    "    std = jnp.sqrt(var)\n",
    "    noise = jr.normal(key, data.shape)\n",
    "    y = mean + std * noise\n",
    "    pred = model(t, y)\n",
    "    return weight(t) * jnp.mean((pred + noise / std) ** 2)\n",
    "\n",
    "\n",
    "def batch_loss_fn(model, weight, int_beta, data, t1, key):\n",
    "    batch_size = data.shape[0]\n",
    "    tkey, losskey = jr.split(key)\n",
    "    losskey = jr.split(losskey, batch_size)\n",
    "    # Low-discrepancy sampling over t to reduce variance\n",
    "    t = jr.uniform(tkey, (batch_size,), minval=0, maxval=t1 / batch_size)\n",
    "    t = t + (t1 / batch_size) * jnp.arange(batch_size)\n",
    "    loss_fn = ft.partial(single_loss_fn, model, weight, int_beta)\n",
    "    loss_fn = jax.vmap(loss_fn)\n",
    "    return jnp.mean(loss_fn(data, t, losskey))\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def single_sample_fn(model, int_beta, data_shape, dt0, t1, key):\n",
    "    def drift(t, y, args):\n",
    "        _, beta = jax.jvp(int_beta, (t,), (jnp.ones_like(t),))\n",
    "        return -0.5 * beta * (y + model(t, y))\n",
    "\n",
    "    term = dfx.ODETerm(drift)\n",
    "    solver = dfx.Tsit5()\n",
    "    t0 = 0\n",
    "    y1 = jr.normal(key, data_shape)\n",
    "    # reverse time, solve from t1 to t0\n",
    "    sol = dfx.diffeqsolve(term, solver, t1, t0, -dt0, y1, adjoint=dfx.NoAdjoint())\n",
    "    return sol.ys[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist():\n",
    "    filename = \"train-images-idx3-ubyte.gz\"\n",
    "    url_dir = \"https://storage.googleapis.com/cvdf-datasets/mnist\"\n",
    "    # target_dir = os.getcwd() + \"/data/mnist\"\n",
    "    target_dir = \"/home/u20200002/Datasets/MNIST\"\n",
    "    url = f\"{url_dir}/{filename}\"\n",
    "    target = f\"{target_dir}/{filename}\"\n",
    "\n",
    "    if not os.path.exists(target):\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "        urllib.request.urlretrieve(url, target)\n",
    "        print(f\"Downloaded {url} to {target}\")\n",
    "\n",
    "    with gzip.open(target, \"rb\") as fh:\n",
    "        _, batch, rows, cols = struct.unpack(\">IIII\", fh.read(16))\n",
    "        shape = (batch, 1, rows, cols)\n",
    "        return jnp.array(array.array(\"B\", fh.read()), dtype=jnp.uint8).reshape(shape)\n",
    "\n",
    "\n",
    "def dataloader(data, batch_size, *, key):\n",
    "    dataset_size = data.shape[0]\n",
    "    indices = jnp.arange(dataset_size)\n",
    "    while True:\n",
    "        perm = jr.permutation(key, indices)\n",
    "        (key,) = jr.split(key, 1)\n",
    "        start = 0\n",
    "        end = batch_size\n",
    "        while end < dataset_size:\n",
    "            batch_perm = perm[start:end]\n",
    "            yield data[batch_perm]\n",
    "            start = end\n",
    "            end = start + batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "def make_step(model, weight, int_beta, data, t1, key, opt_state, opt_update):\n",
    "    loss_fn = eqx.filter_value_and_grad(batch_loss_fn)\n",
    "    loss, grads = loss_fn(model, weight, int_beta, data, t1, key)\n",
    "    updates, opt_state = opt_update(grads, opt_state)\n",
    "    model = eqx.apply_updates(model, updates)\n",
    "    key = jr.split(key, 1)[0]\n",
    "    return loss, model, key, opt_state\n",
    "\n",
    "\n",
    "def main(\n",
    "    # Model hyperparameters\n",
    "    patch_size=4,\n",
    "    hidden_size=64,\n",
    "    mix_patch_size=512,\n",
    "    mix_hidden_size=512,\n",
    "    num_blocks=4,\n",
    "    t1=10.0,\n",
    "    # Optimisation hyperparameters\n",
    "    num_steps=100000,\n",
    "    lr=3e-4,\n",
    "    batch_size=512,\n",
    "    print_every=10_000,\n",
    "    # Sampling hyperparameters\n",
    "    dt0=0.1,\n",
    "    sample_size=10,\n",
    "    # Seed\n",
    "    seed=5678,\n",
    "):\n",
    "    key = jr.PRNGKey(seed)\n",
    "    model_key, train_key, loader_key, sample_key = jr.split(key, 4)\n",
    "    data = mnist()\n",
    "    data_mean = jnp.mean(data)\n",
    "    data_std = jnp.std(data)\n",
    "    data_max = jnp.max(data)\n",
    "    data_min = jnp.min(data)\n",
    "    data_shape = data.shape[1:]\n",
    "    data = (data - data_mean) / data_std\n",
    "\n",
    "    model = Mixer2d(\n",
    "        data_shape,\n",
    "        patch_size,\n",
    "        hidden_size,\n",
    "        mix_patch_size,\n",
    "        mix_hidden_size,\n",
    "        num_blocks,\n",
    "        t1,\n",
    "        key=model_key,\n",
    "    )\n",
    "    int_beta = lambda t: t  # Try experimenting with other options here!\n",
    "    weight = lambda t: 1 - jnp.exp(\n",
    "        -int_beta(t)\n",
    "    )  # Just chosen to upweight the region near t=0.\n",
    "\n",
    "    opt = optax.adabelief(lr)\n",
    "    # Optax will update the floating-point JAX arrays in the model.\n",
    "    opt_state = opt.init(eqx.filter(model, eqx.is_inexact_array))\n",
    "\n",
    "    total_value = 0\n",
    "    total_size = 0\n",
    "    for step, data in zip(\n",
    "        range(num_steps), dataloader(data, batch_size, key=loader_key)\n",
    "    ):\n",
    "        value, model, train_key, opt_state = make_step(\n",
    "            model, weight, int_beta, data, t1, train_key, opt_state, opt.update\n",
    "        )\n",
    "        total_value += value.item()\n",
    "        total_size += 1\n",
    "        if (step % print_every) == 0 or step == num_steps - 1:\n",
    "            print(f\"Step={step} Loss={total_value / total_size}\")\n",
    "            total_value = 0\n",
    "            total_size = 0\n",
    "\n",
    "    sample_key = jr.split(sample_key, sample_size**2)\n",
    "    sample_fn = ft.partial(single_sample_fn, model, int_beta, data_shape, dt0, t1)\n",
    "    sample = jax.vmap(sample_fn)(sample_key)\n",
    "    sample = data_mean + data_std * sample\n",
    "    sample = jnp.clip(sample, data_min, data_max)\n",
    "    sample = einops.rearrange(\n",
    "        sample, \"(n1 n2) 1 h w -> (n1 h) (n2 w)\", n1=sample_size, n2=sample_size\n",
    "    )\n",
    "    plt.imshow(sample, cmap=\"Greys\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 15:17:13.529117: W external/org_tensorflow/tensorflow/compiler/xla/service/gpu/gpu_conv_algorithm_picker.cc:727] None of the algorithms provided by cuDNN heuristics worked; trying fallback algorithms.  Conv: (f32[64,2,4,4]{3,2,1,0}, u8[0]{0}) custom-call(f32[256,2,28,28]{3,2,1,0}, f32[256,64,7,7]{3,2,1,0}), window={size=4x4 stride=4x4}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bw-filter = (f32[64,2,4,4]{3,2,1,0}, u8[0]{0}) custom-call(f32[256,2,28,28]{3,2,1,0} %concatenate.567, f32[256,64,7,7]{3,2,1,0} %bitcast.308), window={size=4x4 stride=4x4}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_name=\"jit(make_step)/jit(main)/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(4, 4) dimension_numbers=ConvDimensionNumbers(lhs_spec=(1, 0, 2, 3), rhs_spec=(1, 0, 2, 3), out_spec=(1, 0, 2, 3)) feature_group_count=1 batch_group_count=1 lhs_shape=(256, 2, 28, 28) rhs_shape=(256, 64, 7, 7) precision=None preferred_element_type=None]\" source_file=\"/home/u20200002/.conda/envs/jax/lib/python3.10/site-packages/equinox/nn/conv.py\" source_line=168}, backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\n\nOriginal error: INTERNAL: All algorithms tried for %cudnn-conv-bw-filter = (f32[64,2,4,4]{3,2,1,0}, u8[0]{0}) custom-call(f32[256,2,28,28]{3,2,1,0} %concatenate.567, f32[256,64,7,7]{3,2,1,0} %bitcast.308), window={size=4x4 stride=4x4}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_name=\"jit(make_step)/jit(main)/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(4, 4) dimension_numbers=ConvDimensionNumbers(lhs_spec=(1, 0, 2, 3), rhs_spec=(1, 0, 2, 3), out_spec=(1, 0, 2, 3)) feature_group_count=1 batch_group_count=1 lhs_shape=(256, 2, 28, 28) rhs_shape=(256, 64, 7, 7) precision=None preferred_element_type=None]\" source_file=\"/home/u20200002/.conda/envs/jax/lib/python3.10/site-packages/equinox/nn/conv.py\" source_line=168}, backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\" failed. Falling back to default algorithm.  Per-algorithm errors:\n  Profiling failure on cuDNN engine eng20{k2=6,k3=0}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on cuDNN engine eng20{k2=8,k3=0}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on cuDNN engine eng21{k6=0,k7=0,k2=0,k4=3,k5=1}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on cuDNN engine eng1{k2=6,k3=0}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on cuDNN engine eng20{k2=7,k3=0}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on cuDNN engine eng0{}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on cuDNN engine eng1{}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on cuDNN engine eng20{}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/u20200002/jupyterlab/hpc/dynamic-unroll-nde/score-based-diffusion/score-based-diffusion.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgpu2-cuda11.2/home/u20200002/jupyterlab/hpc/dynamic-unroll-nde/score-based-diffusion/score-based-diffusion.ipynb#ch0000007vscode-remote?line=0'>1</a>\u001b[0m main()\n",
      "\u001b[1;32m/home/u20200002/jupyterlab/hpc/dynamic-unroll-nde/score-based-diffusion/score-based-diffusion.ipynb Cell 6\u001b[0m in \u001b[0;36mmain\u001b[0;34m(patch_size, hidden_size, mix_patch_size, mix_hidden_size, num_blocks, t1, num_steps, lr, batch_size, print_every, dt0, sample_size, seed)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2-cuda11.2/home/u20200002/jupyterlab/hpc/dynamic-unroll-nde/score-based-diffusion/score-based-diffusion.ipynb#ch0000007vscode-remote?line=59'>60</a>\u001b[0m total_size \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2-cuda11.2/home/u20200002/jupyterlab/hpc/dynamic-unroll-nde/score-based-diffusion/score-based-diffusion.ipynb#ch0000007vscode-remote?line=60'>61</a>\u001b[0m \u001b[39mfor\u001b[39;00m step, data \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2-cuda11.2/home/u20200002/jupyterlab/hpc/dynamic-unroll-nde/score-based-diffusion/score-based-diffusion.ipynb#ch0000007vscode-remote?line=61'>62</a>\u001b[0m     \u001b[39mrange\u001b[39m(num_steps), dataloader(data, batch_size, key\u001b[39m=\u001b[39mloader_key)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2-cuda11.2/home/u20200002/jupyterlab/hpc/dynamic-unroll-nde/score-based-diffusion/score-based-diffusion.ipynb#ch0000007vscode-remote?line=62'>63</a>\u001b[0m ):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgpu2-cuda11.2/home/u20200002/jupyterlab/hpc/dynamic-unroll-nde/score-based-diffusion/score-based-diffusion.ipynb#ch0000007vscode-remote?line=63'>64</a>\u001b[0m     value, model, train_key, opt_state \u001b[39m=\u001b[39m make_step(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2-cuda11.2/home/u20200002/jupyterlab/hpc/dynamic-unroll-nde/score-based-diffusion/score-based-diffusion.ipynb#ch0000007vscode-remote?line=64'>65</a>\u001b[0m         model, weight, int_beta, data, t1, train_key, opt_state, opt\u001b[39m.\u001b[39;49mupdate\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2-cuda11.2/home/u20200002/jupyterlab/hpc/dynamic-unroll-nde/score-based-diffusion/score-based-diffusion.ipynb#ch0000007vscode-remote?line=65'>66</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2-cuda11.2/home/u20200002/jupyterlab/hpc/dynamic-unroll-nde/score-based-diffusion/score-based-diffusion.ipynb#ch0000007vscode-remote?line=66'>67</a>\u001b[0m     total_value \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2-cuda11.2/home/u20200002/jupyterlab/hpc/dynamic-unroll-nde/score-based-diffusion/score-based-diffusion.ipynb#ch0000007vscode-remote?line=67'>68</a>\u001b[0m     total_size \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.10/site-packages/equinox/jit.py:94\u001b[0m, in \u001b[0;36m_JitWrapper.__call__\u001b[0;34m(_JitWrapper__self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(__self, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 94\u001b[0m     \u001b[39mreturn\u001b[39;00m __self\u001b[39m.\u001b[39;49m_fun_wrapper(\u001b[39mFalse\u001b[39;49;00m, args, kwargs)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.10/site-packages/equinox/jit.py:90\u001b[0m, in \u001b[0;36m_JitWrapper._fun_wrapper\u001b[0;34m(self, is_lower, args, kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached\u001b[39m.\u001b[39mlower(dynamic, static)\n\u001b[1;32m     89\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m     dynamic_out, static_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cached(dynamic, static)\n\u001b[1;32m     91\u001b[0m     \u001b[39mreturn\u001b[39;00m combine(dynamic_out, static_out\u001b[39m.\u001b[39mvalue)\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.10/site-packages/jax/_src/dispatch.py:818\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, built_c, options)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39m@profiler\u001b[39m\u001b[39m.\u001b[39mannotate_function\n\u001b[1;32m    815\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackend_compile\u001b[39m(backend, built_c, options):\n\u001b[1;32m    816\u001b[0m   \u001b[39m# we use a separate function call to ensure that XLA compilation appears\u001b[39;00m\n\u001b[1;32m    817\u001b[0m   \u001b[39m# separately in Python profiling results\u001b[39;00m\n\u001b[0;32m--> 818\u001b[0m   \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mcompile(built_c, compile_options\u001b[39m=\u001b[39;49moptions)\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bw-filter = (f32[64,2,4,4]{3,2,1,0}, u8[0]{0}) custom-call(f32[256,2,28,28]{3,2,1,0} %concatenate.567, f32[256,64,7,7]{3,2,1,0} %bitcast.308), window={size=4x4 stride=4x4}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_name=\"jit(make_step)/jit(main)/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(4, 4) dimension_numbers=ConvDimensionNumbers(lhs_spec=(1, 0, 2, 3), rhs_spec=(1, 0, 2, 3), out_spec=(1, 0, 2, 3)) feature_group_count=1 batch_group_count=1 lhs_shape=(256, 2, 28, 28) rhs_shape=(256, 64, 7, 7) precision=None preferred_element_type=None]\" source_file=\"/home/u20200002/.conda/envs/jax/lib/python3.10/site-packages/equinox/nn/conv.py\" source_line=168}, backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\n\nOriginal error: INTERNAL: All algorithms tried for %cudnn-conv-bw-filter = (f32[64,2,4,4]{3,2,1,0}, u8[0]{0}) custom-call(f32[256,2,28,28]{3,2,1,0} %concatenate.567, f32[256,64,7,7]{3,2,1,0} %bitcast.308), window={size=4x4 stride=4x4}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_name=\"jit(make_step)/jit(main)/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(4, 4) dimension_numbers=ConvDimensionNumbers(lhs_spec=(1, 0, 2, 3), rhs_spec=(1, 0, 2, 3), out_spec=(1, 0, 2, 3)) feature_group_count=1 batch_group_count=1 lhs_shape=(256, 2, 28, 28) rhs_shape=(256, 64, 7, 7) precision=None preferred_element_type=None]\" source_file=\"/home/u20200002/.conda/envs/jax/lib/python3.10/site-packages/equinox/nn/conv.py\" source_line=168}, backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\" failed. Falling back to default algorithm.  Per-algorithm errors:\n  Profiling failure on cuDNN engine eng20{k2=6,k3=0}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on cuDNN engine eng20{k2=8,k3=0}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on cuDNN engine eng21{k6=0,k7=0,k2=0,k4=3,k5=1}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on cuDNN engine eng1{k2=6,k3=0}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on cuDNN engine eng20{k2=7,k3=0}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on cuDNN engine eng0{}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on cuDNN engine eng1{}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n  Profiling failure on cuDNN engine eng20{}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning."
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('jax': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3aa1faf8dda839bbdc902e17997852956909f92e1474e5a5c9d8cca37dc72c64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
